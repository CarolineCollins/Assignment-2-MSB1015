---
title: "Assignment 2 MSB1015 Making Multivariate Statistics Reuseable"
author: "Caroline Collins 6192527"
date: "25 September 2019"
output: html_document
---
##Note 
As a prerequisite, this notebook needs a certain Wikidata query R package which you can find here: https://github.com/bearloga/WikidataQueryServiceR

##Project Synopsis

Before running a statistical analysis, we began with some WikiData data that needed to be completed, referenced, inspected, processed and cleaned.
After this came the analysis and modelling, and, finally visualisation of the
results. 
The project process taught us that there are many choices to be made about methods, parameters and variables.
I aimed to document this process in the right level of detail to render the project reproducible. This includes justifying many of the modelling choices. 
The following interactive notebook is an explanation of the steps I performed.

##Computational Chemistry Background

In 1947 Harry Wiener showed a correlation between the physicochemical properties of organic compounds and their chemical structure.
He made a correlation model that linked 
structural features of compounds
with boiling points. 


##Brief Description of the Assignment

In this assignment we use SPARQL to query physicochemical properties from Wikidata for a series of chemical properties,
then make a (PLS) Partial Least Squares model (or similar) 
in an R Markdown notebook with RStudio. 
Note that to correctly use the model for prediction it is necessary to split
the dataset into a training and a test set.
(using 10% or 20% as test set and the remaining for training) 
and also to use cross-validation 
(e.g. Leave-one-Out or Leave-10%-Out) 
An elbow plot will help to estimate the optimal number of latent variables in the predictive model. 
A scatterplot of the model predictions for the test set of the dependent variable (the modelled property) versus the experimental (real, observed) value will serve as a visualisation of the accuracy of the model predictions.
This assignment is part of weeks 4 and 5 of Scientific Programming on the Master's Systems Biology at Maastricht University. ( https://www.maastrichtuniversity.nl/education/master/master-systems-biology )

##Useful sources

Pharmacology: Rang & Dale, ISBN
9780702053627, in that edition Chapter 7 en 60 are of interest
For general knowledge about QSAR, e.g.:
Varnek & Tropsha, Chemoinformatics approaches to virtual screening
Ch. 6 of Kahnâs Recent Trends on QSAR in the Pharmaeutical Perceptions
(ebook)
Wiener H. Structural Determination of Paraffin Boiling Points. Journal of the
American Chemical Society. 1947 Jan;69(1):17-20.
R Markdown: https://rmarkdown.rstudio.com/
Cheatsheet: https://www.rstudio.com/wpcontent/uploads/2016/03/rmarkdown-cheatsheet-2.0.pdf
PLS package for R: https://cran.r-project.org/web/packages/pls/
Vignette: https://cran.r-project.org/web/packages/pls/vignettes/pls- manual.pdf
rcdk package for R:
Vignette/tutorial : https://cran.r-project.org/web/packages/rcdk/vignettes/using-rcdk.html

The WikiData SPARQL endpoint is https://query.wikidata.org/bigdata/namespace/wdq/sparql 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##STEP 0 Set up libraries required for the assignment

```{r}
library("rcdk")
library(pls)
library(WikidataQueryServiceR)
```

##STEP 1 EXECUTE QUERY
Using the R package WikidataQueryServiceR. 
Maintaining the SPARQL query syntax.
The first query checks for any entries still waiting for their  boiling point statements to be entered in WikiData.

SMILES is a text string that represents the compound structure in 2D. ie. it specifies elements, connectivity and bond order, but not the 3D position of each atom.
Examples of SMILES:
ethanol CCO
ethylene C=C
acetylene C#C
2-propanol CC(O)C


P31 is an instance of
P279 is is a subclass of
Q41581 an alkane is an acyclic saturated hydrocarbon
P233 is the canonical SMILES
P2102 is the boiling point
```{r}
sparql_query_missingbp <- 'SELECT DISTINCT ?alkane ?alkaneLabel ?SMILES ?boilingpoint
WHERE {
    ?alkane wdt:P31/wdt:P279* wd:Q41581 .
    ?alkane wdt:P233 ?SMILES .
    MINUS {?alkane wdt:P2102 ?boilingpoint .}
    SERVICE wikibase:label { bd:serviceParam wikibase:language "en"}
}'
results_missingbp = query_wikidata(sparql_query_missingbp)
```
```{r}
sparql_query <- 'SELECT DISTINCT ?alkane ?alkaneLabel ?boilingpoint 
WHERE {
    ?alkane wdt:P31/wdt:P279* wd:Q41581 .
    
    ?alkane wdt:P2102 ?boilingpoint .
    SERVICE wikibase:label { bd:serviceParam wikibase:language "en"}
}'
results_first = query_wikidata(sparql_query)
```
first eyeball of the data
```{r}
range(results_first$boilingpoint)
```
That range has a suspiciously low value. In Kelvin expect all non-negative!
Let's check out the units of the boiling points and 
convert anything non-Kelvin to Kelvin.

The following query is altered from the one provided by Egon  "set up to deal with the complex structure of statements with units in Wikidata." ie it reaches right down into the hierarchical structure of the WikiData  data to extract the various units entered by different WikiData users, and also a human readable label for those units.
```{r}
units_query <- 'SELECT DISTINCT ?alkane ?alkaneLabel ?SMILES ?boilingpoint ?bpUnit ?bpUnitLabel WHERE {
  ?alkane wdt:P31/wdt:P279* wd:Q41581 .
  ?alkane wdt:P233 ?SMILES ;
        p:P2102 [
          ps:P2102 ?boilingpoint ;
          psv:P2102/wikibase:quantityUnit  ?bpUnit
        ] .
  SERVICE wikibase:label { bd:serviceParam wikibase:language "[AUTO_LANGUAGE],en". }
}'
results_bp = query_wikidata(units_query)
possible_units <- unique(results_bp$bpUnitLabel)
possible_units
```

getting the boiling points out of the WikiData DB
the problem is that some of them are in Celsius and others in Fahrenheit.
Convert units and change unitlabels across the dataset.
```{r}

results_bp$boilingpoint[results_bp$bpUnitLabel == "degree Celsius"] <- results_bp$boilingpoint[results_bp$bpUnitLabel == "degree Celsius"] + 273.15
results_bp$bpUnitLabel[results_bp$bpUnitLabel == "degree Celsius"] <- "kelvin"
results_bp$boilingpoint[results_bp$bpUnitLabel == "degree Fahrenheit"] <- (results_bp$boilingpoint[results_bp$bpUnitLabel == "degree Fahrenheit"]-32)*5/9 + 273.15
results_bp$bpUnitLabel[results_bp$bpUnitLabel == "degree Fahrenheit"] <- "kelvin"
```
quick check
```{r}
unique(results_bp$bpUnitLabel)
```
```{r}
head(results_bp$boilingpoint)
```
##Eyeball the data
```{r}
range(results_bp$boilingpoint)
```
```{r}
plot.default(results_bp$boilingpoint)
```
Check the distribution of the input data
```{r}
hist(results_bp$boilingpoint)
```
The boiling points are not normally distributed.
It will be important to check the distribution of the training and test sets later to verify that neither is biased or skewed.


Chemistry beginner's question:
Does the length of the SMILES string correlate with the boiling point?
```{r}
plot(nchar(results_bp$SMILES),results_bp$boilingpoint)
```
the correlation between the boiling point and the string length of the SMILES looks good!!
```{r}
cor(nchar(results_bp$SMILES),results_bp$boilingpoint)
```
##Collect variables which we expect to be informative of boiling point
try and translate the data that I have , in the form of SMILES, into what we need out of the database in order to do the regression. For this use R package rcdk.
ie the descriptors that you derive from the SMILES from QSAR(?) using rcdk
(parse.smiles function)
These will give a collection of descriptors
which you can use as variables,
then generate latent variables with PLS.
##Descriptors with rcdk
rcdk  allows us to access the cheminformatics functionality of the CDK from within R.
There is a list of descriptors here https://cdk.github.io/cdk/1.5/docs/api/org/openscience/cdk/qsar/descriptors/molecular/package-tree.html
I can also learn about descriptors in the rcdk documentation.
https://cran.r-project.org/web/packages/rcdk/vignettes/using-rcdk.html

##Explore rcdk
The molecule objects (that result from load.molecules) are of class jobjRef (provided by the rJava package). As a result,they are pretty opaque to the user and are really meant to be processed using methods from the rcdk or rJava packages.

Another common way to obtain molecule objects is by parsing SMILES strings. The simplest way to do this is eg
```{r}
smile <- 'c1ccccc1CC(=O)C(N)CC1CCCCOC1'
mol <- parse.smiles(smile)[[1]]
```
Usage is more efficient when multiple SMILE are supplied, since then a single SMILES parser object is used to parse all the supplied SMILES.
(from the rcdk tutorial -see useful sources)
A key requirement for the predictive modeling of molecular properties and activities are molecular descriptors - numerical charaterizations of the molecular structure. 
The CDK implements a variety of molecular descriptors, categorized.

It is possible to evaluate all available descriptors at one go, or evaluate individual descriptors.
Each descriptor name (eg "org.openscience.cdk.qsar.descriptors.molecular.WHIMDescriptor") is  a fully qualified Java class name for the corresponding descriptor. 
These names can be supplied to eval.desc to evaluate a single or multiple descriptors for one or more molecules.

Explore CDK Get the descriptor categories
```{r}
dc <- get.desc.categories()
dc
```


Explore CDK Get the descriptor names for category 4  - electronic
```{r}
dn <- get.desc.names(dc[4])

allDescs <- eval.desc(mol, dn)
```
Note: for this particular molecule and this set of descriptors, the majority are NA
with the exception of bpol and apol, the sum of the atomic polarizabilities and the sum of the absolute value of the difference between atomic polarizabilities of all bonded atoms in the molecule respectively.
Note: The return value of eval.desc is a data.frame with the descriptors in the columns and the molecules in the rows. For the above example we get a single row. But given a list of molecules, we can easily get a descriptor matrix.

The list of descriptor names used here comes from the rcdk tutorial (https://cran.r-project.org/web/packages/rcdk/vignettes/using-rcdk.html) the example in which the are also interested in predicting boiling points from organic molecules.
```{r}
mols <- parse.smiles(results_bp$SMILES)
descNames_limited <- c(
 'org.openscience.cdk.qsar.descriptors.molecular.KierHallSmartsDescriptor',
 'org.openscience.cdk.qsar.descriptors.molecular.APolDescriptor',
 'org.openscience.cdk.qsar.descriptors.molecular.HBondDonorCountDescriptor')
descriptors_limited <- eval.desc(mols, descNames_limited)
```
Note: this gives 81 variables across the molecules list. Some will be NA, nevertheless 81 variables from 3 descriptors is a lot more than I expected. Prompting the question how many variables would there be from the complete set of around 50 descriptors?
```{r}
anyNA(descriptors_limited)
```
Confirms that , as mentioned in the tutorial, these descriptors have been chosen to not return NAs.
Nevertheless, this code, preparatory to building a presictive model from the descriptor matrix, is set up to remove
NA,
correlated,
and constant columns from the matrix.
```{r}
#remove NAs
descriptors_limited <- descriptors_limited[, !apply(descriptors_limited, 2, function(x) any(is.na(x)) )]
#remove constant columns
descriptors_limited <- descriptors_limited[, !apply( descriptors_limited, 2, function(x) length(unique(x)) == 1 )] #no. of variables drops from 81 to 5 on running this
#crudely remove highly correlated columns - alternative caret , GA, leaps, feature selectn
r2 <- which(cor(descriptors_limited)^2 > .6, arr.ind=TRUE)
r2 <- r2[ r2[,1] > r2[,2] , ]
descriptors_limited <- descriptors_limited[, -r2] #reduces to 3 variables
r2
```
```{r}
head(descriptors_limited)
```
Add boiling point to this
```{r}
descriptor_matrix_1 <- cbind(descriptors_limited, results_bp$boilingpoint)
library(plyr)
descriptor_matrix_1 <- rename(descriptor_matrix_1,c("results_bp$boilingpoint" = "boilingpoint"))       #renames awkward column name (uses dplyr package)
```

##Choosing suitable variables for the predictive model
Here there are two opposing approaches to building the model:
purely data-driven throw the kitchen sink at it, uses all the available descriptors (how many datapoints is that?), followed by dimension reduction and then predicts based on the optimum number of latent variables. (bp_model_2)
vs a more knowledge-based approach (bp_model_1). By eg. searching the descriptor list on "Weiner", "boiling point", "complexity" and handpicking likely important variables (this is the approach used in the rcdk vignette). The r pls package PLS method still employs principal component analysis, so our prediction will still run on latent variables anyway.


##STEP 2 MULTIVARIATE STATISTICS Partial Least Squares vs Multilinear Regression
##Split dataset into Trainng and Test
In this case the rows are not ranked, but ideally, to make the code universally reusable
I should randomly sample away a percentage of the matrix row dimension to be the test set.
And assign the remainder to be train.
For now, time restraints, bash out a result, use this:
```{r}

bp_train <- descriptor_matrix_1[1:100,]
bp_test <- descriptor_matrix_1[-(1:100),]
```
Check the distribution of the boiling points of the two datasets
```{r}
hist(bp_test$boilingpoint)
```
Satisfactory: the independent test set has a similar distribution to the full set of alkanes. Though none in the lowest range.
Now check the distribution of boiling points of the training set
```{r}
hist(bp_train$boilingpoint)
```


Make first model
There are only 3 variables
No surprise
```{r}


bp_model_1 <- plsr(boilingpoint ~. ,ncomp = 3, data = bp_train, validation = "CV")
summary(bp_model_1)
```
```{r}
plot(RMSEP(bp_model_1), legendpos = "topright")
```
What's the predictive power of this very basic model with 2 parameters?
```{r}
plot(bp_model_1, ncomp = 2, asp = 1, line = TRUE)
```


predict on the test set
```{r}
pred_bp_1 <- predict(bp_model_1, ncomp = 2, newdata = bp_test)
plot(pred_bp_1,bp_test$boilingpoint)
```

```{r}
RMSEP(bp_model_1, newdata = bp_test)
```
This is not a satisfactory model.
It does not perform well at predicting the boiling points of compounds in the training set.

##Model 2 kitchen sink version
Get all the descriptors possible 

```{r}
descNames <- unique(unlist(sapply(get.desc.categories(), get.desc.names))) #50 descriptors
dn_all <- eval.desc(mols, descNames) #286 variables
```
Into one big decriptor_matrix_2
remove correlated, constant and NA columns as before
```{r}
anyNA(dn_all)
#remove NAs
desc_all <- dn_all[, !apply(dn_all, 2, function(x) any(is.na(x)) )]
#results in 219 variables (before was 286 variables)
#Add boiling point to this to make the descriptor matrix
descriptor_matrix_2 <-  cbind(desc_all, results_bp$boilingpoint)
#note rename() needs library(plyr)
descriptor_matrix_2 <- rename(descriptor_matrix_2,c("results_bp$boilingpoint" = "boilingpoint"))       #renames awkward column name (uses dplyr package)
```
Split the training and test sets.
```{r}
bp_train_2 <- descriptor_matrix_2[(1:100),]
bp_test_2 <- descriptor_matrix_2[-(1:100),]
```
Make a big model
```{r}
bp_model_2 <- plsr(boilingpoint ~., data = bp_train_2, ncomp = 10, validation = "CV" )
summary(bp_model_2)
```
Things to bear in mind: covariance,
normalise
scale
scores and loadings
CROSS-VALIDATION method : package offers "CV" and "LOO"


```{r}
plot(RMSEP(bp_model_2), legendpos = "topright")
```
What's the predictive power of this data-driven model?
```{r}
plot(bp_model_2, ncomp = 5, asp = 1, line = TRUE)
```
##STEP 3 VISUALISATION Scatterplot Predicted boiling pt vs Observed in Test dataset
Predict boiling points of the test set
```{r}
pred_bp_2 <- predict(bp_model_2, ncomp = 5, newdata = bp_test_2)
plot(pred_bp_2,bp_test_2$boilingpoint, abline(a= 0, b = 1))

```

```{r}
RMSEP(bp_model_2, newdata = bp_test_2)
```





##STEP 4 Further
Report prediction errors 
Compare to literature and/or simple model 
Repeat and apply to **more chemical structures** 
Explain the differences in results
